# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Di_yFWFUNRYwaM4LJV3OUwZ34pxCd7VS
"""

!pip install -q streamlit openai transformers accelerate bitsandbytes diffusers pillow
!npm install -g localtunnel

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import torch
# import os
# import gc
# from PIL import Image
# from transformers import Blip2Processor, Blip2ForConditionalGeneration, CLIPProcessor, CLIPModel
# from diffusers import StableDiffusionXLImg2ImgPipeline
# from openai import OpenAI
# 
# # --- UI CONFIGURATION (Dark Theme) ---
# st.set_page_config(page_title="AI Interior Designer", layout="wide")
# st.markdown("""
#     <style>
#     .stApp { background-color: #0e1117; color: white; }
#     .stSidebar { background-color: #262730; }
#     .card { background-color: #1a1c24; padding: 20px; border-radius: 10px; border: 1px solid #4a4a4a; }
#     </style>
#     """, unsafe_allow_html=True)
# 
# # --- CACHE MODELS FOR SPEED ---
# @st.cache_resource
# def load_vision_models():
#     # BLIP-2 for room analysis
#     processor_blip = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
#     model_blip = Blip2ForConditionalGeneration.from_pretrained(
#         "Salesforce/blip2-opt-2.7b", device_map="auto", load_in_8bit=True
#     )
#     # CLIP for accuracy scoring
#     model_clip = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
#     processor_clip = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
#     return processor_blip, model_blip, processor_clip, model_clip
# 
# @st.cache_resource
# def load_sdxl():
#     # SDXL for redesigning the room visually
#     pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
#         "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
#     )
#     pipe = pipe.to("cuda")
#     return pipe
# 
# # --- MAIN APP UI ---
# st.title("üè† AI-Powered Interior Design Generator")
# 
# with st.sidebar:
#     st.header("Settings")
#     api_key = st.text_input("OpenAI API Key (GPT-3.5)", type="password")
#     style_choice = st.selectbox("Redesign Style", ["Modern", "Scandinavian", "Industrial", "Bohemian", "Minimalist"])
#     room_type = st.selectbox("Room Type", ["Living Room", "Bedroom", "Kitchen", "Office"])
#     uploaded_file = st.file_uploader("Upload Room Image", type=["jpg", "jpeg", "png"])
# 
# if uploaded_file and api_key:
#     # 1. Image Setup
#     image = Image.open(uploaded_file).convert("RGB")
#     st.image(image, caption="Current Room Layout", width=500)
# 
#     if st.button("Generate Redesign"):
#         with st.spinner("Processing Models (BLIP-2 + CLIP + GPT-3.5 + SDXL)..."):
#             # Init Client and Models
#             client = OpenAI(api_key=api_key)
#             p_blip, m_blip, p_clip, m_clip = load_vision_models()
# 
#             # 2. BLIP-2: Detect Objects & Layout
#             inputs = p_blip(images=image, return_tensors="pt").to("cuda", torch.float16)
#             gen_ids = m_blip.generate(**inputs, max_new_tokens=50)
#             room_desc = p_blip.batch_decode(gen_ids, skip_special_tokens=True)[0].strip()
# 
#             # 3. CLIP: Accuracy Assessment
#             inputs_clip = p_clip(text=[room_desc], images=image, return_tensors="pt", padding=True)
#             clip_out = m_clip(**inputs_clip)
#             acc_val = torch.sigmoid(clip_out.logits_per_image).item() * 100
# 
#             # 4. GPT-3.5 Turbo: Design Consultant
#             prompt = f"Act as an interior designer. Review this room: {room_desc}. Provide a {style_choice} redesign plan."
#             response = client.chat.completions.create(
#                 model="gpt-3.5-turbo",
#                 messages=[{"role": "user", "content": prompt}]
#             )
#             design_advice = response.choices[0].message.content
# 
#             # 5. SDXL: Visual Transformation
#             sd_pipe = load_sdxl()
#             redesign_img = sd_pipe(
#                 prompt=f"A professional high-quality {style_choice} {room_type}, photorealistic, architectural digest style",
#                 image=image,
#                 strength=0.65,
#                 guidance_scale=7.5
#             ).images[0]
# 
#             # --- DISPLAY RESULTS ---
#             st.divider()
#             col1, col2 = st.columns(2)
#             with col1:
#                 st.subheader("Visual Analysis (BLIP-2)")
#                 st.write(room_desc)
#                 st.metric("Model Confidence (CLIP)", f"{acc_val:.1f}%")
# 
#             with col2:
#                 st.subheader("Redesigned Visual (SDXL)")
#                 st.image(redesign_img, use_container_width=True)
# 
#             st.subheader("Redesign Strategy (GPT-3.5)")
#             st.markdown(design_advice)
# 
#             # Cleanup
#             gc.collect()
#             torch.cuda.empty_cache()
# else:
#     st.info("Please enter your OpenAI API key and upload a room image to begin.")





